+++ Transcript to lalr.log started at Fri May 06 22:22:55 2016 +++
Codemist Standard Lisp 8.00 revision 3648 for win64: May  6 2016
Created: Mon May 02 22:39:42 2016

REDUCE (3632), 02-May-16 ...
Memory allocation: 117 Mbytes
There are 8 processors available

+++ About to read file "lalr1.tst"


nil


nil


nil

% Parser generator using LALR techniques as used by yacc etc

module lalr;


nil


% Author: Arthur Norman

% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions are met:
%
%    * Redistributions of source code must retain the relevant copyright
%      notice, this list of conditions and the following disclaimer.
%    * Redistributions in binary form must reproduce the above copyright
%      notice, this list of conditions and the following disclaimer in the
%      documentation and/or other materials provided with the distribution.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
% AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
% THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
% PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNERS OR
% CONTRIBUTORS
% BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
% CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
% SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
% INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
% CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
% ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
% POSSIBILITY OF SUCH DAMAGE.
%

% $Id: lalr.red 3137 2015-06-15 09:45:01Z arthurcnorman $

% The module genparser contains code that can create LALR parsing
% tables, while yyparse has a hand-written lexer suitable for use with
% Rlisp syntax together with the skeleton of an LR parser which can use
% the tables that are generated by genparser.

create!-package('(lalr genparser genparserprint yylex yyparse), nil);


lalr


switch tracelex, lalr_verbose;


nil


global '(lex_char yylval last64 last64p which_line if_depth);


nil

global '(next_lex_code);


nil

global '(dot_char rpar_char rsquare_char);


nil


global '(goto_index goto_old_state goto_new_state);


nil

global '(action_index, action_terminal action_result);


nil

global '(action_first_error action_error_messages);


nil

global '(action_fn action_a action_n);


nil


global '(terminals non_terminals symbols goto_cache action_map);


nil

fluid '(renamings);


nil


#if (memq 'psl lispsystem!*)

% CSL has special vectors that hold just 8-bit integers (it also has ones
% for 16-bit integers) and use of those will decrease the amount of
% memory consumed by the parser tables. However if PSL does not have these
% it does not matter much since I can just use ordinary Lisp vectors...
% I set initial contents as all 0 rather than all nil since these are
% supposed to contain (small) integer values.

symbolic procedure mkvect8 n;
  begin
    scalar r;
    r := mkvect n;
    for i := 0:n do putv(r, i, 0);
    return r
  end;

inline procedure putv8(v, n, x); putv(v, n, x);

inline procedure getv8(v, n); getv(v, n);

procedure mkvect16 n;
  begin
    scalar r;
    r := mkvect n;
    for i := 0:n do putv(r, i, 0);
    return r
  end;

inline procedure putv16(v, n, x); putv(v, n, x);

inline procedure getv16(v, n); getv(v, n);


% Other CSL-isms that need simulation in PSL.

% If PSL does not have built-in hash tables I will model the
% effect that they provide using association lists. To arrange that
% a "table" can be updated in place I will have a list of length 1
% whose sole element is the association list. This code just uses
% EQUAL tests for hash table membership.

symbolic procedure mkhash(size, equality_mode, expansion_factor);
   list nil;

symbolic procedure puthash(key, table, value);
  begin
    scalar w;
    w := assoc(key, car table);
    if w then rplacd(w, value)
    else rplaca(table, (key . value) . car table);
    return value
  end;

symbolic procedure gethash(key, table);
  begin
    scalar w;
    w := assoc(key, car table);
    if w then return cdr w
    else return nil
  end;

symbolic procedure hashcontents table;
  car table;

symbolic procedure ttab n;
  tab n;

load gsort; % Not loaded by default and not autoloaded on demand.

symbolic procedure sort(ll, ff);
  gsort(ll, ff);

#endif


endmodule;


nil


end;

nil

% yylex.red

% Author: Arthur Norman, with changes by Zach Hauser, 2016

% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions are met:
%
%    * Redistributions of source code must retain the relevant copyright
%      notice, this list of conditions and the following disclaimer.
%    * Redistributions in binary form must reproduce the above copyright
%      notice, this list of conditions and the following disclaimer in the
%      documentation and/or other materials provided with the distribution.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
% AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
% THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
% PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNERS OR
% CONTRIBUTORS
% BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
% CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
% SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
% INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
% CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
% ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
% POSSIBILITY OF SUCH DAMAGE.
%

% $Id: yylex.red 3061 2015-03-30 10:31:50Z arthurcnorman $

module 'yylex;


nil


%
% This is a lexical anaylser for use with RLISP. Its interface is
% styles after the one needed by yacc, in that it exports a function
% called yylex() that returns as a value a category code, but
% sets a variable yylval to details associated with the item
% just parsed. The result will be an integer corresponding to a token
% type.

% Before using this lexer all the special tokens that it must handle
% must be passed to it. These are passed as strings. Some of these
% will be purely made up out of letters and would otherwise be treated
% a "symbols" but when advised about them the code here will allocate
% a category code and treat them as keywords. Thus one might have
%     lex_keywords '("if" "else" "begin" "end");
% These cases do not have any effect on how the lexer groups characters
% to form tokens, but do alter the result it gives in the cases concerned.
% Note that in RLISP an exclamation mark escapes the following character
% so it can appear in a symbol. A name written with one or more exclamation
% marks will never be treated as a keyword, and so even if the input 'begin'
% is special any of the inputs '!begin', 'b!egin' or '!b!e!g!i!n' (and of
% course many other variants) just yield a symbol.
%
% The second case is of keyword made up from punctuation marks. It is
% required (at least to start with) that keywords are either entirely
% alphanumeric or entirely punctuation. If no keywords have been set up then
% punctuation characters form single-character symbols. Thus for instance
% the input 'a:=b' would tokenise as a sequence of four symbols, 'a', ':',
% '=' and 'b'. If a multi-characters string has been passed to lex_keywords
% then dipthongs can be formed, so after
%     lex_keywords '(":=");
% the same input would tokenise to 3 items, the symbols 'a', a keyword ':='
% and then the symbol 'b'.
% If a sequence  punctuation marks is passed the behaviour is as if each
% prefix had been to. Thus after the above plus
%     lex_keywords '("<==>");
% the behaviour is just as if the user had presented
%     lex_keywords '(":" ":=" "<" "<=" "<==" "<==>");
% and any grammar using the lexer may thus need to deal with the intermediate
% cases.
%
% Input that is not exactly the string of characters making up a keyword will
% not be read as a keyword. That means that escape characters (!) have an
% effect. For alphanumeric cases the result will just be a symbol
%     beg!in            is the symbol whose name is 'begin'.
% For punctuation sequences an exclamation mark terminates a token and
% starts another (which will then always be a symbol). So
%     <=!=>             is the keyword '<=' followed by the
%                       symbol '=' followed by the keyword or symbol '>',
%                       much as if it had been written as '<= != >' with
%                       extra whitespace to make eveything clearer. 
%
% lex_keywords can be called multiple times so you do not have to declare
% all your keywords at once.
%
% After use of the lexer it will be desirable to call lex_cleanup() which
% will discard all tables and other information that was created. It will
% typically be vital to do this before starting to create a fresh grammar!
%
% To use the lexer call lex_init() and then repeatdly call yylex();
%
% At present this design provides for having just one lexer (and its tables)
% available at a time. I could imagine wanting to have several available
% for different purposes - the extension of this interface to support that
% case is something I will worry about later - maybe!

global '(lex_keyword_names lex_next_code lex_initial_next_code lex_codename);


nil


% The various primitive lex types have pre-set codes. These exist once
% and for all so get established on a static base here.

%   :eof           End of file
%   :symbol        Either a single punctuation character that has not
%                  been declared as a keyword, or a letter followed
%                  by letters, digits and underscores, also excluding
%                  cases that are keywords, or any other string of
%                  characters with leading digits or underscores and any
%                  punctuation marks preceeded by exclamation marks.
%   :string        Enclosed in double quotes. To include a double quote
%                  within a string double it, as in "with ""inside"" quotes".
%   :number        Either an integer or a floating point value. I will need
%                  to review whether non-decimal representations for
%                  integers (eg 0xff) are supported.
%   :list          Either a quote or a backquote followed by Lisp-like
%                  data, for instance 'word or `(template ,sub1 ,@sub2 end).

put('!:eof,    'lex_fixed_code, 0);


0

put('!:symbol, 'lex_fixed_code, 1);


1

put('!:string, 'lex_fixed_code, 2);


2

put('!:number, 'lex_fixed_code, 3);


3

put('!:list,   'lex_fixed_code, 4);


4


% lex_codename is just used when generating trace output and maps from
% numeric codes back to the corresponding terminal symbols. Because it isd
% only used for tracing I am not concerned about performance and I will use
% a simple association list.

lex_codename := '((0 . !:eof) (1 . !:symbol) (2 . !:string)
                  (3 . !:number) (4 . !:list));


((0 . !:eof) (1 . !:symbol) (2 . !:string) (3 . !:number) (4 . !:list))


% All further terminals are given codes beyond the range used for the
% primitive ones.

lex_initial_next_code := lex_next_code := 5;


5


lex_keyword_names := nil;


nil


global '(lex_escaped
         lex_eof_code lex_symbol_code lex_number_code
         lex_string_code lex_list_code);


nil


lex_eof_code    := get('!:eof,    'lex_fixed_code);


0

lex_symbol_code := get('!:symbol, 'lex_fixed_code);


1

lex_number_code := get('!:number, 'lex_fixed_code);


3

lex_string_code := get('!:string, 'lex_fixed_code);


2

lex_list_code   := get('!:list,   'lex_fixed_code);


4



% I will treat just very plain letters as items that can be in
% alphanumeric keywords. By "very plain" I mean the letters A-Z and
% a-x in the range U+0000 to U+007f. So accented letters. Greek letters and
% letters with style variations (eg small caps, fullwidth (U+ff41 et seq),
% mathematical (eg U+1d41a et seq)) are not treated as things that could
% make a simple symbol without the nees for escapes. 

symbolic procedure lex_unicode_alphabetic c;
  (c >= 0x41 and c <= 0x5a) or (c >= 0x61 and c <= 0x7a);

+++ lex_unicode_alphabetic compiled, 24 + 24 bytes

lex_unicode_alphabetic


% Similarly only basic Latin digits can be used in numbers. "Other language"
% digits and mathematical presentation forms will not count.

symbolic procedure lex_unicode_numeric c;
  (c >= 0x30 and c <= 0x39);

+++ lex_unicode_numeric compiled, 12 + 16 bytes

lex_unicode_numeric


symbolic procedure lex_keywords l;
  for each x in l do
    begin
      scalar w, ok, pre;
% I will see what all the characters in the string are. By using
% widestring2list I get the codes for those characters even if some
% are over U+00FF. The resulting list is a list of integers...
      w := widestring2list x;
      if null w then rederr "Empty string passed to lex_keywords";
% Now I will check if the string starts with a letter and continues
% with letters, digits and underscores...
      ok := lex_unicode_alphabetic car w;
      for each c in cdr w do
        if not lex_unicode_alphabetic c and
           not lex_unicode_numeric c and
           c neq 0x5f then ok := nil;      % 0x5f is '_'
      if null cdr w or ok then << % Simple case without dipthong consequences
        w := intern x;
        if null get(w, 'lex_code) then <<
          lex_keyword_names := w . lex_keyword_names;
          put(w, 'lex_code, lex_next_code);
          lex_codename := (lex_next_code . w) . lex_codename;
          if !*tracelex then <<
            princ "Token '";
            prin w;
            princ "' allocated code ";
            print lex_next_code >>;
          lex_next_code := lex_next_code + 1 >>;
        return >>; % remember that RETURN just exits the begin/end block.
% Now I have something that may be introducing a dipthong. I will set things
% up so that each case where there is a prefix "ABC" "X" that the token "ABC"
% is a keyword and then I will go
%    put(ABC, 'lex_dipthong, (X . ABCX) . get(abc, 'lex_dipthing))
     x := intern x;
     if not get(x, 'lex_code) then << % may have been seen already
        lex_keyword_names := x . lex_keyword_names;
        put(x, 'lex_code, lex_next_code);
        lex_codename := (lex_next_code . x) . lex_codename;
        lex_next_code := lex_next_code + 1;
% Recurse to deal with prefixes...
        pre := list2widestring reverse cdr reverse w;
        lex_keywords list pre;
        pre := intern pre;
        w := intern list2widestring list lastcar w;
        if !*tracelex then <<
          if not zerop posn() then terpri();
          princ "dipthong data '";
          prin pre;
          princ "' plus '";
          prin w;
          princ "' => '";
          prin x;
          printc "'" >>;
        put(pre, 'lex_dipthong, (w . x) . get(pre, 'lex_dipthong)) >>;
    end;

+++ lex_keywords compiled, 223 + 92 bytes

lex_keywords


symbolic procedure lex_cleanup();
  begin
% Note that !:symbol etc retain their lex_code properties since the values
% they have are universal.
    for each x in lex_keyword_names do <<
      remprop(x, 'lex_code);
      remprop(x, 'lex_dipthong) >>;
    lex_keyword_names := nil;
    lex_next_code := lex_initial_next_code;
    lex_codename := '((0 . !:eof) (1 . !:symbol) (2 . !:string)
                      (3 . !:number) (4 . !:list));
  end;

+++ lex_cleanup compiled, 30 + 36 bytes

lex_cleanup


% The following pair of procedures provide for switching back and forth  
% between "different lexers".
% 
% Specifically, lex_save_context() returns some data that, when fed back into 
% lex_restore_context(), should have everything right back at the point after 
% you made your lex_keywords calls but before you called lex_init(). 
symbolic procedure lex_save_context();
  mapcar(lex_codename,
    function (lambda w; get(intern cdr w, 'lex_dipthong) . w));

+++ lex_save_context compiled, 26 + 16 bytes

lex_save_context


symbolic procedure lex_restore_context(context);
  begin
    scalar token, dipthong, code;
    lex_cleanup();
    for each x in context do <<
      dipthong := car x; code := cadr x; token := intern cddr x; 
      if not get(token, 'lex_fixed_code) then <<
        if code > lex_next_code then lex_next_code := code;
        put(token, 'lex_dipthong, dipthong);
        put(token, 'lex_code, code);
        lex_codename := (code . token) . lex_codename;
        lex_keyword_names := token . lex_keyword_names >> >>
  end;

+++ lex_restore_context compiled, 65 + 40 bytes

lex_restore_context


% This procedure returns an association list mapping from integer category 
% codes (same as returned by yylex()) to tokens (as symbols). The list is 
% ordered by category code (decreasing). 
%
% If the lexer's internals are changed around such that lex_codename 
% disappears (perhaps, is replaced by a hash table), this should continue
% to export the same structure for consumption by other code, like 
% the parser generator.
symbolic procedure lex_export_codes(); 
  sort(lex_codename, function ordopcar);

+++ lex_export_codes compiled, 4 + 20 bytes

lex_export_codes
 %% does this do what i think

% I keep a circular buffer with the last 64 characters that have been
% read. Initially the buffer contains NILs rather than characters, so I can
% tell when it is only partially filled. I have tagged yyreadch() inline
% because it is probably one of the time-critical parts of the entire
% parsing process.

% Note that in CSL (ar least) readch will return a character and it will
% interpret UTF-8 multi-byte sequences as single characters where necessary.
% So this code is (at least on CSL) unicode friendly.

symbolic procedure yyreadch();
 << lex_char := readch();
    if lex_char = !$eol!$ then which_line := which_line + 1;
    if lex_char neq !$eof!$ then << 
      last64p := last64p + 1;
      if last64p = 64 then last64p := 0;
      putv(last64, last64p, lex_char) >>;
    lex_char >>;

+++ yyreadch compiled, 32 + 40 bytes

yyreadch


symbolic procedure yyerror msg;
  begin
    scalar c;
    terpri();
    prin2 "+++++ Parse error at line "; prin1 which_line; prin2 ":";
    if atom msg then msg := list msg;
    for each s in msg do << prin2 " "; prin2 s >>;
    terpri();
    for i := 1:64 do <<
      last64p := last64p + 1;
      if last64p = 64 then last64p := 0;
      c := getv(last64, last64p);
      if not (c = nil) then prin2 c >>;
    if not (c = !$eol!$) then terpri();
    if lex_char = !$eof!$ then printc "<EOF>"
  end;

+++ yyerror compiled, 89 + 68 bytes

yyerror


% Before a succession of calls to yylex() it is necessary to
% ensure that lex_char is set suitably and that the circular buffer
% used to store characters for error messages is ready for use.

global '(lex_peeked);


nil


symbolic procedure lex_init();
 << last64 := mkvect 64;
    last64p := 0;
    which_line := 1;
    if_depth := 0;
    if !*tracelex then <<
      if posn() neq 0 then terpri();
      printc "yylex initialized" >>;
    lex_peeked := nil;
    yyreadch() >>;

+++ lex_init compiled, 30 + 52 bytes

lex_init


%
% The following version of YYLEX provides RLISP with a facility for
% conditional compilation.  The protocol is that text is included or
% excluded at the level of tokens.  Control by use of new reserved
% tokens #if, #else and #endif.  These are used in the form:
%    #if (some Lisp expression for use as a condition)
%    ... RLISP input ...
%    #else
%    ... alternative RLISP input ...
%    #endif
%
% The form
%    #if C1 ... #elif C2 ... #elif C3 ... #else ... #endif
% is also supported.
%
% Conditional compilation can be nested.  If the Lisp expression used to
% guard a condition causes an error it is taken to be a FALSE condition.
% It is not necessary to have an #else before #endif if no alternative
% text is needed. Although the examples here put #if etc at the start of
% lines this is not necessary (though it may count as good style?). Since
% the condition will be read using RLISPs own list-reader there could be
% condtional compilation guarding parts of it - the exploitation of that
% possibility is to be discouraged!
%
% Making the condition a raw Lisp expression makes sure that parsing it
% is easy. It makes it possible to express arbitrary conditions, but it is
% hoped that most conditions will not be very elaborate - things like
%    #if (not (member 'csl lispsystem!*))
%         error();
%    #else
%         magic();
%    #endif
% or
%    #if debugging_mode   % NB if variable is unset that counts as nil
%    print "message";      % so care should be taken to select the most
%    #endif               % useful default sense for such tests
% should be about as complicated as reasonable people need.
%
% NOTE: in the implementation of this in rlisp/tok.red there was for
% some time a bug whereby
%  #if t ; ... ; #elif x ; ... ; #else XXX #endif
% included the text XXX because #else was taken as just flipping the
% acceptance state. I need to review and test the code here to ensure that
% it does not suffer from the same badness!
% 
% Two further facilities are provided:
%    #eval (any lisp expression)
% causes that expression to be evaluated at parse time.  Apart from any
% side-effects in the evaluation the text involved is all ignored. It is
% expected that this will only be needed in rather curious cases, for
% instance to set system-specific options for a compiler.
%
%    #define symbol value
% where the value should be another symbol, a string or a number, causes
% the first symbol to be mapped onto the second value wherever it occurs in
% subsequent input.  No special facility for undoing the effect of a
% #define is provided, but the general-purpose #eval could be used to
% remove the '#define property that is involved. The result generated this
% was is not re-scanned and can not end up being treated as a preprocessor
% directive.
%
% NOTE: The special symbols #if etc are NOT recognised within Lisp
%       quoted expressions, so test like the following will be
%       ineffective:
%            a := '(
%                P
%            #if q_is_wanted
%                Q
%            #endif
%                R);
%       but on the other hand code like
%            if sym = '!#if then ...
%       behaves the way that had probably been wanted. Unlike the C
%       preprocessor, this system recognizes directives within rather than
%       just at the start of lines.


symbolic procedure yylex();
  begin
    scalar w, done;
% I take a rather robust view here - words that are intended to be used as
% keywords may not be written with included escape characters. Thus for
% instance this lexer will view "be!gin" or "!begin" as being a simple
% symbol and NOT being the keyword "begin".
    w := lex_basic_token();
% The "while not done" loop is so that I can restart the scan after seeing
% a pre-processor directive such as #if.
    while not done do <<
% The word "COMMENT" introduces a comment that terminates at the next ";"
% or "$". But note that "co!mment" (for instance) would not since that will
% be classifed as a symbol not as a keyword because of the embedded escape.
% So if you REALLY want to have a symbol with name "comment" in your input
% you can write it as (again for instance) "!comment" so it is not processed
% here. Ha ha ha "comment" is now a keyword in that it will never generate
% a lexer-code to pass back as a result. But it is recognised in the same
% sort of circumstances that keywords are.
    while w = lex_symbol_code and yylval = 'COMMENT and
          not lex_escaped do <<
      while not (lex_char = '!; or lex_char = '!$) do yyreadch();
      yyreadch();
      w := lex_basic_token() >>;
% If a word was spelt out directly (without any escape characters in it) it
% may be a keyword - if it is, then deal with it it here.
    if w = lex_symbol_code and not lex_escaped then <<
% #define provides a simple (very simple) macro substitution scheme that is
% probably too limited to be really useful.
      if done := get(yylval, '!#define) then <<
        yylval := done;
        if numberp done then w := lex_number_code
        else if stringp done then w := lex_string_code;
        done := t >> 
      else done := t >>
% A word with escapes in might be a pre-processor directive because I will
% allow "!#if" as well as "#if" to be used. That is going to require
% lex_basic_token() to accept #if (and other cases) directly.
    else if w = lex_symbol_code then <<
% Note that the conditional compilation keywords are not recognised within
% quoted expressions, so "'!#if" is safe here.
      if yylval eq '!#if then <<
        read_s_expression();
        w := lex_conditional yylval >>
      else if yylval eq '!#else or
              yylval eq '!#elif then <<
        if if_depth = 0 then yyerror "Unexpected #else of #elif"
        else if_depth := if_depth-1;
        yylval := nil;
        w := lex_skipping(w, nil) >>
      else if yylval eq '!#endif then <<
        if if_depth = 0 then yyerror "Unexpected #endif"
        else if_depth := if_depth-1;
        w := lex_basic_token() >>
      else if yylval eq '!#eval then << 
        read_s_expression();
        errorset(yylval, nil, nil);
        w := lex_basic_token() >>
      else if yylval eq '!#define then <<
        read_s_expression();
        w := yylval;    % Ought to be a symbol, number of string
        done := read_s_expression();
        if idp w or numberp w or stringp w then
          put(w, '!#define, done);
        w := lex_basic_token();
        done := nil >>
      else if not lex_escaped then <<
        if done := get(yylval, '!#define) then <<
          yylval := done;
          if numberp done then w := lex_number_code
          else if stringp done then w := lex_string_code;
          done := t >>
        else done := t >>
      else done := t >>
    else done := t >>;
    if !*tracelex then <<
      if posn() neq 0 then terpri();
      prin2 "yylex = "; prin1 yylval; prin2 " type "; print w >>;
    return w;
  end;

+++ yylex compiled, 275 + 140 bytes

yylex




% If, when reading ordinary text, I come across the token #if I read
% the expression following. If that evaluates to TRUE I just keep on
% on reading. So the sequence "#if t" is in effect ignored. Then
% if later on I just ignore an "#endif" all will be well.  If on the other
% hand the expression evaluates to NIL (or if evaluation fails), I will
% call lex_skipping() to discard more tokens (up to and including
% the next "#else", "#elif t" or "#endif"). I keep a count of how many
% "#if t" equivalents I have passed so that I can match them with their
% corresponding "#endif" statements and moan if an "#else" or "#endif"
% occurs out of place.

symbolic procedure lex_conditional x;
  begin
    scalar w;
    w := lex_basic_token();
    x := errorset(x, nil, nil);
    if errorp x or null car x then return lex_skipping(w, nil);
    if_depth := if_depth+1;
    return w
  end;

+++ lex_conditional compiled, 27 + 24 bytes

lex_conditional


% I call lex_skipping when I find "#if nil" or "#else" or "#elif"
% that is processed. When a top-level "#else" or "#elif" is found it
% is discarded before calling lex_skipping, since it must follow a
% successful "#if" and hence introduce material to be thrown away.

symbolic procedure lex_skipping(w, x);
  begin
    scalar done;
% In this code x keep track of the depth of testing of "#if" constructions
    while not done do <<
      if w = lex_eof_code then done := t   % End of file
      else <<
        if w = '!:symbol then <<
          if yylval = '!#endif then <<
            if null x then done := t
            else x := cdr x >>
          else if yylval = '!#if then x := nil . x
          else if yylval = '!#else and null x then done := t
          else if yylval = '!#elif and null x then <<
            read_s_expression();
            done := errorset(yylval, nil, nil);
            if errorp done or null car done then done := nil >> >>;
      w := lex_basic_token() >> >>;
    return w
  end;

+++ lex_skipping compiled, 81 + 52 bytes

lex_skipping



% lex_basic_token() will read the next token from the current input stream
% and leave a value in yylval to show what was found.
% It recognize the quote prefix, as in '(lisp expression) and
% `(backquoted thing).  The return value is a numeric code.
% It leaves a variable lex_escaped true if the "word" that was
% read had any "!" characers used to escape parts of it.

global '(lex_peeked lex_peeked_yylval lex_peeked_escaped);


nil


symbolic procedure lex_basic_token();
  begin
    scalar r, w;
% The item I peeked ahead and read will have started with a letter or an
% exclamation mark so should be a :symbol or some keyword, and not either
% a number or a string. And one further key fact is that it can not have
% started with a "#".
% Oh dear, what about the input
%     #!#if
% well that will return # and then #if, and because the inner "#if" is
%  introduced with an exclamation mark it can not cause nested attempts at
% look-ahead. Whew.
    if lex_peeked then <<
      r := lex_peeked;
      yylval := lex_peeked_yylval;
      lex_escaped := lex_peeked_escaped;
      lex_peeked := lex_peeked_yylval := lex_peeked_escaped := nil;
      return r >>;
    lex_escaped := nil;
% First skip over whitespace. Note that at some stage in the future RLISP
% may want to make newlines significant and partially equivalent to
% semicolons, but that is not supported at present.
    while lex_char = '!  or lex_char = !$eol!$ or
% I treat from "%" to the en dof a line as being comment.
          (lex_char = '!% and <<
            while not (lex_char = !$eol!$ or lex_char = !$eof!$) do yyreadch();
            t >>) do yyreadch();
% Symbols start with a letter or an escaped character and continue with
% letters, digits, underscores and escapes.
    if liter lex_char or
       (lex_char = '!! and <<
          yyreadch() where !*raise = nil, !*lower = nil;
          lex_escaped := t >>) then <<
      r := lex_char. r;
      while yyreadch() = '!_ or
            liter lex_char or
            digit lex_char or
            (lex_char = '!! and <<
               yyreadch() where !*raise = nil, !*lower = nil;
               lex_escaped := t >>) do r := lex_char . r;
% If there was a '!' in the word I will never treat it as a keyword.
% That situation is spottable by virtue of the variable lex_escaped.
% Note that list2widestring is passed a list of symbols here not integers,
% bur recent implementations of it support that case.
      yylval := intern list2widestring reversip r;
%     if !*tracelex then <<
%       princ "symbol is '"; prin yylval;
%       princ "' lex_escaped="; prin lex_escaped;
%       princ " lex_code="; print get(yylval, 'lex_code) >>;
      if not lex_escaped and (w := get(yylval, 'lex_code)) then return w
      else return lex_symbol_code >>
% Numbers are either integers or floats. A floating point number is
% indicated by either a point "." or an exponent marker "e". In the code
% here I keep a flag (in w) to indicate if I had a floating or integer
% value, but in the end I ignore this and hand back the lexical category
% for :number in both cases. At present I will not handle radix specifiers.
    else if digit lex_char then <<
      r := list lex_char;
      while << yyreadch(); digit lex_char >> do r := lex_char . r;
      if lex_char = '!. then <<
        w := t;       % Flag to indicate floating point
        r := lex_char . r;
        while << yyreadch(); digit lex_char >> do r := lex_char . r >>;
% I permit the user to write the exponent marker in either case.
      if lex_char = '!e or lex_char = '!E then <<
% If the input as 1234E56 I expand it as 1234.0E56
        if not w then r := '!0 . '!. . r;
        w := t;
        r := '!e . r;
        yyreadch();
        if lex_char = '!+ or lex_char = '!- then <<
          r := lex_char . r;
          yyreadch() >>;
% If there is no digit written after "E" I insert a zero. Thus overall the
% input 17E gets treated as 17.0E0
        if not digit lex_char then r := '!0 . r
        else <<
          r := lex_char . r;
          while << yyreadch(); digit lex_char >> do r := lex_char . r >> >>;
% Here I have a number, so I can use compress to parse it.
      yylval := compress reversip r;
      return lex_number_code >>
% Strings are enclosed in double-quotes, and "abc""def" is a string with
% a double-quote mark within it. Note no case folding on characters in a
% string.
    else if lex_char = '!" then <<
      begin
        scalar !*raise, !*lower;      % Make !*raise & !*lower both nil.
        repeat <<
          while not (yyreadch() = '!") do r := lex_char . r;
          r := lex_char . r;
          yyreadch() >> until not (lex_char = '!");
      end;
      yylval := list2widestring reversip cdr r;
      return lex_string_code >>
% "'" and "`"(backquote) introduce Lisp syntax S-expressions
    else if lex_char = '!' then <<
      yyreadch();
      read_s_expression();
      yylval := list('quote, yylval);
      return lex_list_code >>
    else if lex_char = '!` then <<
      yyreadch();
      read_s_expression();
      yylval := list('backquote, yylval);
      return lex_list_code >>
    else <<
      yylval := lex_char;
% I take special notice of end of file, since it is fairly drastic.
% In particular I do not attempt to advance lex_char beyond it. So I do
% TWO things here: I avoid advancing the input, and I return the lex_eof_code
% as an end-of-file indication.
      if yylval = !$eof!$ then return lex_eof_code;
      if yylval = '!# or get(yylval, 'lex_dipthong) then yyreadch()
      else lex_char := '! ;  % Try to avoid reading beyond where I HAVE to.
% There is a bit of horribly magic needed here. I want
%  #if #else #elif #endif #eval and #define
% to be accepted without needing an initial exclamation mark.
% The spelling "!#if" (etc) will already have been coped with,
% it is the case with no escape character I am concered
% about here, and that requires a 1-symbol look-ahead. Well even there
% the look ahead only has to consider a whole symbol if the character after
% the "#" is a letter (or an "!").
      if yylval = '!# and liter lex_char or lex_char = '!! then <<
        r := lex_basic_token();
% Observe that I only check yylval here not the type of token returned.
% That is because words like "if" and "define" stand a real chance of being
% keywords! For this to be safe it is important that lex_basic_token
% always updates yylval whatever it returns.
        if memq(yylval,'(if else elif endif define eval)) then <<
          yylval := intern list2widestring(
                      '!# . widestring2list symbol!-name yylval) >>
        else <<   % set up the peeked token for later processing.
          lex_peeked := r;
          lex_peeked_yylval := yylval;
          lex_peeked_escaped := lex_escaped;
          yylval := '!#;
          lex_escaped := nil >> >>;
        while w := atsoc(lex_char, get(yylval, 'lex_dipthong)) do <<
          yylval := cdr w;
          yyreadch() >>;
      if w := get(yylval, 'lex_code) then return w
      else return lex_symbol_code >>
  end;

+++ lex_basic_token compiled, 438 + 168 bytes

lex_basic_token


%
% I use a hand-written recursive descent parser for Lisp S-expressions
% mainly because the syntax involved is so VERY simple. A rough sketch of
% the syntax required is given here, but in reality (in part because I do
% not want to have to report syntax errors) I implement a more liberal
% syntax, especially as it relates to dotted-pair notation. This of course
% is one of the natural dangers in using recursive descent... the syntax
% actually parsed is only properly defined by direct reference to the code.
%

% s_tail      =   ")" |
%                 "." s_expr ")" |
%                 s_expr s_tail;
% 
% s_vectail   =   "]" |
%                 s_expr s_vectail;
% 
% s_expr      =   symbol |
%                 number |
%                 string |
%                 "(" s_tail |
%                 "[" s_vectail |
%                 "'" s_expr |
%                 "`" s_expr |
%                 "," s_expr |
%                 ",@" s_expr;

dot_char     := char!-code '!.;


46

rpar_char    := char!-code '!);


41

rsquare_char := char!-code '!];


93


symbolic procedure read_s_expression();
 <<
% At the start of an S-expression I want to check for the characters
% "(", "[" and ",". Thus I need to skip whitespace.
    while lex_char = '!  or lex_char = '!$eol!$ do yyreadch();
    if lex_char = '!( then begin
      scalar r, w, w1;
      yyreadch();
      w := read_s_expression();
      while not (w = rpar_char or w = dot_char or w = 0) do <<
        r := yylval . r;
% Note that at the end of the list read_s_expression() will read the ")"
% as a token.
        w := read_s_expression() >>;
      if not (w = dot_char) then yylval := reversip r
      else <<
        read_s_expression();  % Thing after the "."
        w := yylval;
% Reverse the list putting a dotted item on the end.
        while r do <<
          w1 := cdr r;
          rplacd(r, w);
          w := r;
          r := w1 >>;
        yylval := w;
        while lex_char = '!  or lex_char = '!$eol!$ do
            yyreadch();
% When I find a ")" I do not read beyond it immediately, but reset lex_char
% to whitespace. This may help prevent unwanted hangups in interactive use.
        if lex_char = '!) then lex_char := '!   % turn ')' into a blank.
        else yyerror "Syntax error with '.' notation in a list" >>;
      return '!:list end
% "[" introduces a simple vector.
    else if lex_char = '![ then begin
      scalar r, w, w1;
      yyreadch();
      w := read_s_expression();
      w1 := -1;
      while not (w = rsquare_char or w = 0) do <<
        r := yylval . r;
        w1 := w1 + 1;
        w := read_s_expression() >>;
% Create a vector of the correct size and copy information into it.
      w := mkvect w1;
      r := reversip r;
      w1 := 0;
      while r do <<
        putv(w, w1, car r);
        w1 := w1 + 1;
        r := cdr r >>;
      yylval := w;
      return '!:list end
% I spot "," and ",@" here, and should wonder if I should (a) police that
% they are only expected to make sense within the scope of a "`" and (b)
% whether I ought to expand them in terms of LIST, CONS, APPEND etc here.
% For now I just hand back markers that show where they occured.
    else if lex_char = '!, then <<
      yyreadch();
      if lex_char = '!@ then <<
        yyreadch();
        read_s_expression();
        yylval := list('!,!@, yylval) >>
      else <<
        read_s_expression();
        yylval := list('!,, yylval) >>;
      'list >>
% Care with ")" and "]" not to read ahead further than is essential.
    else if lex_char = '!) or lex_char = '!] or lex_char = '!. then <<
      yylval := lex_char;
      lex_char := '! ;
      char!-code yylval >>      
% In most cases (including "'" and "`") I just hand down to read a token.
% This covers the cases of symbols, numbers and strings.
    else lex_basic_token() >>;

+++ read_s_expression compiled, 209 + 100 bytes

read_s_expression



endmodule;


nil


end;

nil

% yyparse.red

module 'yyparse;


nil


% Copyright Zach Hauser and Arthur Norman, 2016

% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions
% are met:
%
%    * Redistributions of source code must retain the relevant
%      copyright notice, this list of conditions and the following
%      disclaimer.
%    * Redistributions in binary form must reproduce the above
%      copyright notice, this list of conditions and the following
%      disclaimer in the documentation and/or other materials provided
%      with the distribution.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
% "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
% LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
% A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
% OWNERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
% SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
% LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
% DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
% THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
% (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
% OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
% 

% $Id: $

%==============================================================================
% This is a general-purpose LR(1) parser skeleton. The entry point is the 
% function yyparse, which receives a parameter "parser" containing all the info 
% necessary to parse a specific grammar. (Note: genparser.red will generate
% LALR parsers in the format yyparse expects.)
%
% This parser skeleton is based on the method given by the Dragon Book. 
% Consequently, the "parser" passed to yyparse consists of the ACTION and GOTO
% tables described in the Dragon Book, along with some other additional info
% required for their operation.
%==============================================================================

% parser_action_table is the ACTION table described in the Dragon Book, with
% some (optional) effort at compaction. The format is a vector of "table rows", 
% indexed by parser state. Each row is a dotted pair (row . default), where 
% "row" is an alist from terminal to action and "default" is an optional default 
% action to take if "row" does not have an entry for the desired terminal. 
% 
% Terminals are represented as the integer category codes returned by yylex().
% 
% Actions are also integers, where positive x indicates "shift to state x" and 
% and negative x indicates "reduce by reduction code (-x-1)". Since state 0 is
% the initial state of an augmented grammar, the ACTION table will never 
% prescribe a shift to state 0, and so we use 0 to indicate "accept".
%
% A blank entry in the ACTION table (i.e., no entry in "row" and no default)
% indicates an error.
%
% parser_goto_table is the GOTO table in a similar format. This time, the 
% vector elements are "table columns" indexed by nonterminal. The column alists
% are from source state to destination state, and the default is not optional. 
%
% Note that nonterminals are represented as integer codes as well.
fluid '(parser_action_table parser_goto_table);


nil


% These three vectors are indexed by reduction code (as found in the ACTION 
% table), and are referred to when executing a reduction. 
% For a given reduction code:
%   - reduction_rhs_n holds the number of symbols on the right-hand-side of the 
%     production, i.e. the number of states to be popped off the state stack
%     and the number of values to be popped off the symbol stack.
%
%   - reduction_fn contains an optional semantic action function, which is 
%     passed the values popped off the symbol stack and returns the value
%     pushed on to the symbol stack. There is default behavior for when no 
%     semantic action is provided, described below in yyparse.
%
%   - reduction_lhs contains the nonterminal on the left-hand-side of the 
%     production, as its integer nonterminal code. This is then used to lookup
%     the destination state from the GOTO table, to push onto the state stack.
% 
% Note that reduction_lhs and reduction_rhs_n are CSL fixnum vectors.
fluid '(reduction_fn reduction_lhs reduction_rhs_n);


nil


% This is an alist from nonterminal category code to nonterminal symbol, 
% provided strictly for verbose printing purposes. Note that genparserprint.red
% provides a lalr_prin_nonterminal function that expects a global/fluid called
% nonterminal_codes to be initialized in this format b B convenient!
fluid '(nonterminal_codes);


nil


% This function deconstructs the parser structure passed to yyparse() and 
% initialized all the necessary fluid variables. 
%
% The final element of the parser structure not yet mentioned (because it's not
% stored as a fluid variable above) is the lex_context structure that needs
% to be passed to lex_restore_context (in yylex.red) so that the lexer will 
% provide the correct tokens for this grammar.
symbolic procedure set_parser parser;
  <<
    lex_restore_context(car parser);
    parser_action_table := cadr parser;
    reduction_fn := car caddr parser;
    reduction_rhs_n := cadr caddr parser;
    reduction_lhs := caddr caddr parser;
    parser_goto_table := cadddr parser;
    nonterminal_codes := cadddr cdr parser
  >>;

+++ set_parser compiled, 31 + 36 bytes

set_parser


symbolic procedure get_goto(src_state, nonterminal);
  begin
    scalar table_column_and_default, table_column, result;
    table_column_and_default := getv(parser_goto_table, nonterminal); 
    table_column := car table_column_and_default;
    result := cdr table_column_and_default;
    while table_column do 
      if caar table_column = src_state then <<
        result := cdar table_column;
        table_column := nil >>
      else
        table_column := cdr table_column;
    return result
  end;

+++ get_goto compiled, 27 + 12 bytes

get_goto


symbolic procedure get_action_without_lookahead state;
  begin
    scalar table_row_and_default;
    table_row_and_default := getv(parser_action_table, state);
    if car table_row_and_default = nil then
      return cdr table_row_and_default
    else
      return nil
  end;

+++ get_action_without_lookahead compiled, 11 + 12 bytes

get_action_without_lookahead


symbolic procedure get_action(state, terminal);
  begin
    scalar table_row_and_default, table_row, result;
    table_row_and_default := getv(parser_action_table, state);
    table_row := car table_row_and_default;
    result := cdr table_row_and_default;
    while table_row do 
      if caar table_row = terminal then <<
        result := cdar table_row;
        table_row := nil >>
      else
        table_row := cdr table_row;
    return result
  end;

+++ get_action compiled, 27 + 12 bytes

get_action


symbolic procedure yyparse parser;
  begin
    % state_stack is a stack of parser-machine states and sym_stack runs
    % in step with it and holds the corresponding symbols. Terminals are 
    % shifted directly onto sym_stack, but when a nonterminal is generated
    % through a reduction, the sym_stack receives the result of the semantic 
    % action.
    scalar parser_action_table, parser_goto_table, 
           reduction_fn, reduction_lhs, reduction_rhs_n, 
           nonterminal_codes,
           sym_stack, state_stack, next_input, w;


    % Note that state 0 must be the initial state, and that we initialize
    % next_input to an invalid code -1 which is used to avoid unnecessary 
    % reading ahead.
    set_parser parser;
    state_stack := list 0;
    lex_init();
    next_input := -1; 

    % Each iteration of the loop begins by fetching the next action. The loop
    % ends when the input is accepted (action 0) or on error (action nil).
    while <<
      w := get_action_without_lookahead(car state_stack);
      if null w then <<
        if next_input < 0 then next_input := yylex();
        w := get_action(car state_stack, next_input) >>;
      (w neq 0) and (w neq nil) >> 
    do <<

      % SHIFT
      if w > 0 then <<                            
        if next_input < 0 then next_input := yylex();
        if next_input = 0 then error(0, "End of file detected");
        if next_input = lex_symbol_code or
          next_input = lex_number_code or
          next_input = lex_string_code or
          next_input = lex_list_code then
          sym_stack := yylval . sym_stack
        else sym_stack := next_input . sym_stack;    
        state_stack := w . state_stack;                 
        next_input := -1;                               
        if !*lalr_verbose then << %% should we decode the terminal code here?
          princ "Shift token "; prin car sym_stack; princ " onto stack, ";
          princ "and shift to state "; print car state_stack >> >>

      % REDUCE
      else begin                                   
        scalar lhs, rhs_n, fn;
        w := -w;
        fn := getv(reduction_fn, w);
        rhs_n := getv8(reduction_rhs_n, w);             
        lhs := getv16(reduction_lhs, w);            
        w := nil;
        for i := 1:rhs_n do <<
          w := car sym_stack . w;
          sym_stack := cdr sym_stack;
          state_stack := cdr state_stack >>;

        % By default, if no semantic action is provided, we either:
        %   - build the list (r1 r2 r3) for a production of multiple symbols
        %     L -> r1 r2 r3
        %   - simply leave r unchanged for a production of one symbol L -> r
        if fn then w := apply(fn, w)
        else if rhs_n = 1 then w := car w;
        sym_stack := w . sym_stack;

        state_stack := get_goto(car state_stack, lhs) . state_stack;

        if !*lalr_verbose then <<
          princ "On lookahead "; prin next_input; princ ", reduce "; prin rhs_n; 
          princ " symbols to nonterminal "; lalr_prin_nonterminal lhs; 
          princ ", and goto state "; print car state_stack >>
      end >>;

    if w = nil then <<
      terpri();
      yyerror(nil);
      princ "states: "; print state_stack;
      princ "symbols: "; print sym_stack;
      princ "next token: "; print next_input >>;

    if !*lalr_verbose then <<
      if not zerop posn() then terpri();
      princ "Seems to have finished... " >>;

    return car sym_stack
  end;
*** yyparse defined with 1 but previously called with 0 arguments 


+++ yyparse compiled, 310 + 156 bytes

yyparse


endmodule;


nil


end;

nil

% genparser.red


%==============================================================================
% This is a LALR(1) parser generator, which takes the specification of an 
% appropriate grammar and outputs a parser for that grammar. The parser 
% consists of a set of tables and other information intended to be used by
% yyparse.red's yyparse() procedure. 
%
% The core algorithm is the "efficient" construction given by the Dragon Book,
% where the LR(0) itemset collection is generated and then transformed into
% the LALR itemset collection by a process of spontaneous generation and
% propagation of lookaheads.
%==============================================================================

% Copyright Zach Hauser and Arthur Norman, 2016

% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions
% are met:
%
%    * Redistributions of source code must retain the relevant
%      copyright notice, this list of conditions and the following
%      disclaimer.
%    * Redistributions in binary form must reproduce the above
%      copyright notice, this list of conditions and the following
%      disclaimer in the documentation and/or other materials provided
%      with the distribution.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
% "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
% LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
% A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
% OWNERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
% SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
% LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
% DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
% THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
% (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
% OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
% 

% $Id: $

%==============================================================================
% Fluid Variables & Symbol Properties (& general notes)
%==============================================================================

% These four structures are created early on by lalr_set_grammar() for later
% reference. The first two are lists of grammar symbols: symbols contains 
% all nonterminals and terminals, while nonterminals contains only those. 
%
% This is a logical place to explain that, after lalr_set_grammar() does its 
% work, nonterminals are represented as Lisp symbols while terminals are 
% represented by their respective lexer category codes (integers), obtained 
% from yylex.red. For this reason, the code occasionally uses numberp and idp 
% to determine whether a particular grammar symbol is a terminal or nonterminal.
%
% lex_context is the data structure representing a particular parser's lexer. 
% It is obtained from lex_save_context() in yylex.red in order to be later
% fed into lex_restore_context() to "switch back" to the appropriate lexer. 
% It is not examined or deconstructed in this file, but merely stored early on
% in order to be included in the final structure representing the parser that
% is constructed.
%
% The precedence_table stores information about the precedence and 
% associativity of terminals (if provided). It is a vector indexed by terminal
% (i.e., by lexer category code), where each entry is a dotted pair of 
% precedence (an integer, with 0 indicating the highest precedence and higher 
% numbers indicating lower precedence) and associativity (!:right, !:left, or
% !:none). lalr_precedence and lalr_associativity are provided as convenience
% functions for reading from the precedence_table. 
fluid '(symbols nonterminals lex_context precedence_table);


nil


symbolic procedure lalr_precedence terminal;
  begin 
    scalar x;
    if (x := getv(precedence_table, terminal)) then
      return car x
  end;

+++ lalr_precedence compiled, 9 + 12 bytes

lalr_precedence


symbolic procedure lalr_associativity terminal;
  begin 
    scalar x;
    if (x := getv(precedence_table, terminal)) then 
      return cdr x
  end;

+++ lalr_associativity compiled, 9 + 12 bytes

lalr_associativity


% The following structure is provided for use by genparserprint.red, in which 
% lives all the code for printing diagnostic information during the parser 
% generation process. It is a simple association list from lexer category code
% to the terminal as a Lisp symbol.
fluid '(terminal_codes nonterminal_codes);


nil


fluid '(reduction_info);


nil


% Together, the following two structures represent the collection of itemsets 
% (first LR(0) and then LALR) used to construct the parsing tables.
%
% The itemset_collection is a list of indexed itemsets (dotted pair of itemset   
% and integer index), where each itemset is a list of items. Initially, when 
% the items are LR(0), the item [A -> ab.cd] would be represented as simply 
%         '(A a b !. c d). 
% When the items are LALR, the item [A -> ab.cd, u/v/x] would be represented as 
%         '((A a b !. c d) u v x). 
%
% The goto_table describes the GOTO transitions between the itemsets. It is 
% implemented as a hashtable of alists, as follows. If B = GOTO(A, X) where 
% A,B are itemsets and X is a grammar symbol (terminal or nonterminal), then 
% gethash(X, goto_table) will return an alist containing the entry (A . B). 
% Note that A,B are the actual indexed itemset objects from itemset_collection.
%
% lalr_add_goto and lalr_goto are provided as convenience functions
% for constructing and reading from the goto_table.
%
% Both itemset_collection (as the LR(0) collection) and goto_table are  
% initially constructed by lalr_generate_lr0_collection(), and 
% lalr_generate_collection() then modifies itemset_collection by adding 
% lookaheads to convert it into the LALR collection.  
fluid '(itemset_collection goto_table);


nil


symbolic procedure lalr_add_goto(src, x, dest);
  puthash(x, goto_table, (src . dest) . gethash(x, goto_table));

+++ lalr_add_goto compiled, 19 + 20 bytes

lalr_add_goto


symbolic procedure lalr_goto(src, x);
  begin 
    scalar result_i_itemset;
    if result_i_itemset := assoc(src, gethash(x, goto_table)) then
      return cdr result_i_itemset 
    else  
      return nil
  end;

+++ lalr_goto compiled, 16 + 16 bytes

lalr_goto


% In addition to the fluid variables described above, we store data relating 
% to each nonterminal in its property list (temporarily lalr_cleanup() clears 
% these properties out at the very end). 
% 
% For some nonterminal X:
% 
% 'lalr_produces holds a list of productions, where each production is a dotted
% pair of right-hand-side and semantic action. For example, if there is a 
% production [X -> a "+" b {plus !$1 !$3}], then the list of productions will
% include '((a "+" b) plus !$1 !$3).
% 
% 'lalr_first holds the list of terminals that make up the FIRST set of X, as
% defined by the Dragon Book.
%
% 'lalr_nonterminal_code holds a unique integer code for X. These are assigned
% by lalr_set_grammar() but not actually used until the construction of the 
% parser tables. (As mentioned, throughout almost all the parser generation, 
% code, nonterminals are stored as Lisp symbols).
%
% lalr_productions is a convenience function for accessing the 'lalr_produces
% property.

symbolic procedure lalr_productions x;
  get(x, 'lalr_produces);
*** SMACRO/INLINE lalr_productions redefined 


+++ lalr_productions compiled, 4 + 12 bytes

lalr_productions


%==============================================================================



%==============================================================================
% lalr_create_parser() main driver function and entry point for genparser.red,
%                        and its cleanup function lalr_cleanup().
%==============================================================================

% This function is the entry point for genparser.red -- ideally the only 
% function that users of this code need to worry about. It receives the 
% complete description of a grammar, and returns a LALR parser for that grammar.
%
% precedence_list: an optional (can be nil) list of operator precedence
%                  declarations, ordered by decreasing precedence. Each element
%                  of the list is either 
%                     - a single terminal symbol
%                     - a list of terminal symbols (which indicates that they 
%                       all share the same precedence level)
%                     - an associativity directive (!:right, !:left, or !:none),
%                       which applies until the next associativity directive in
%                       the list (note: the default associativity is !:left)
%                  For example:
%                     '(!:right "^" !:left ("*" "/") ("+" "-") !:none "=")
% 
% grammar: the grammar is passed as a list of rules. Each rule is a dotted pair
%          of nonterminal and a list of productions, where each production is a
%          dotted pair of right-hand-side and semantic action. For example, the
%          toy expression grammar
%             expr   -> expr "+" expr { plus !$1 !$3 } | 
%                       expr "*" expr { times !$1 !$3 } | 
%                       number 
%             number -> "~" <number> { minus !$1} |
%                       <number>
%          would be represented by the structure
%             '((expr   ((expr "+" expr) plus !$1 !$3)
%                       ((expr "*" expr) times !$1 $3)
%                       ((number)))
%               (number (("~" !:number) minus !$1)
%                       ((!:number))))
%          Note that terminals are represented by strings or one of the special
%          tokens recognized by the core lexer: !:symbol, !:string, or !:number.  %% test and add the others
%          Nonterminals are represented by symbols. 
%
% returns: a structure representing a complete LALR parser (and associated 
%          lexer) for the given grammar. The structure is intended to be passed
%          as the argument to yyparse() in yyparse.red. 
symbolic procedure lalr_create_parser (precedence_list, grammar);
  begin

    % These are the fluid variables described above and used by the rest of the 
    % code, plus the parser tables themselves.
    scalar symbols, nonterminals, lex_context, precedence_table, 
           terminal_codes, itemset_collection, goto_table, 
           reduction_info, compressed_action_table, compressed_goto_table;

    % Analyze the grammar, setting fluid variables and symbol properties
    % for further reference and modification. After this, we don't need to 
    % look at the arguments (precedence_list and grammar) again.
    lalr_set_grammar(precedence_list, grammar);

    % Generate the LR(0) itemset collection and then convert it to the final 
    % LALR(1) itemset collection. After this, all the fluid variables are in
    % their final state.
    goto_table := mkhash(length symbols, 1, 1.5);
    lalr_generate_lr0_collection();
    lalr_generate_collection();

    % Assign each unique "reduction" a numerical code and store the relevant
    % information for each reduction in a single structure. The parser's action
    % table will refer to each reduction by its code.
    reduction_info := lalr_process_reductions();

    % Analyze the LALR(1) itemset collection to create the parser's action
    % and goto tables (as described by the Dragon Book).  
    compressed_action_table := lalr_make_compressed_action_table();
    compressed_goto_table := lalr_make_compressed_goto_table();

    % The only global state we've polluted is the nonterminal symbols' 
    % property lists, so we clean that up here. 
    lalr_cleanup();

    return list(lex_context, compressed_action_table, reduction_info, 
                compressed_goto_table, nonterminal_codes)
  end;
*** lalr_set_grammar called with 2 instead of 1 arguments 


+++++ global symbols converted to fluid
+++ lalr_create_parser compiled, 54 + 72 bytes

lalr_create_parser
 

symbolic procedure lalr_cleanup();
  for each symbol in symbols do <<
    put(symbol, 'lalr_produces, nil);
    put(symbol, 'lalr_first, nil);
    put(symbol, 'lalr_nonterminal_code, nil) >>;

+++ symbols declared fluid
+++ lalr_cleanup compiled, 31 + 28 bytes

lalr_cleanup


%==============================================================================



%==============================================================================
% lalr_set_grammar()   this section analyzes the precedence_list and grammar
%                      structure, stashing all the information the rest of the
%                      code will need in fluid variables and symbol property
%                      lists. 
%==============================================================================

symbolic procedure lalr_set_grammar(precedence_list, grammar);
  begin
    scalar terminals; 

    grammar := lalr_augment_grammar grammar;

    nonterminals := lalr_collect_nonterminals grammar;
    terminals := lalr_collect_terminals grammar;
    terminal_codes := lalr_get_lex_codes terminals;
    lalr_set_nonterminal_codes();

    precedence_table := lalr_create_precedence_table (precedence_list, 
                                                      terminal_codes);

    lalr_process_productions(grammar, terminal_codes);

    lalr_precalculate_first_sets();

    terminals := for each terminal in terminals collect  
                    car rassoc(intern terminal, terminal_codes);
    symbols := append(nonterminals, terminals);

    if !*lalr_verbose then <<
      lalr_print_terminals_and_codes terminals;
      lalr_print_nonterminals_and_productions();
      lalr_print_first_information() >>
  end;
*** lalr_set_grammar defined with 2 but previously called with 1 arguments 


+++++ global terminals converted to fluid
+++ lalr_set_grammar compiled, 97 + 84 bytes

lalr_set_grammar


symbolic procedure lalr_augment_grammar grammar;
  begin
    if assoc('!S!', grammar) then
      return grammar
    else 
      return list('!S!', list list caar grammar) . grammar
  end;

+++ lalr_augment_grammar compiled, 17 + 12 bytes

lalr_augment_grammar


symbolic procedure lalr_create_precedence_table (precedence_list, lex_codes);
  begin
    scalar table, associativity, next_precedence, terminal_code;
    table := mkvect caar lex_codes;
    next_precedence := 0;
    associativity := '!:left;
    for each x in precedence_list do <<
      if x member '(!:left !:none !:right) then 
        associativity := x
      else <<
        for each xx in (if atom x then list x else x) do <<
          terminal_code := car rassoc(intern xx, lex_codes);
          putv(table, terminal_code, next_precedence . associativity) >>;
        next_precedence := next_precedence + 1 >> >>;
    return table
  end;

+++ lalr_create_precedence_table compiled, 76 + 24 bytes

lalr_create_precedence_table


symbolic procedure lalr_set_nonterminal_codes;
  begin
    scalar code;
    code := 0;
    for each x in nonterminals do <<
      if x = '!S!' then 
        put(x, 'lalr_nonterminal_code, -1)
      else <<
        put(x, 'lalr_nonterminal_code, code);
        if !*lalr_verbose then 
          nonterminal_codes := (code . x) . nonterminal_codes;
        code := code + 1 >> >>;
      if !*lalr_verbose then 
        nonterminal_codes := ((-1) . '!S!') . nonterminal_codes;
  end;

+++ lalr_set_nonterminal_codes compiled, 56 + 40 bytes

lalr_set_nonterminal_codes


symbolic procedure lalr_process_productions(grammar, lex_codes);
  begin
    scalar x, productions, productions_processed, w, rule, semantic_action;
    for each productions in grammar do <<
      x := car productions;
      productions_processed := nil;
      for each production in cdr productions do <<
        rule := car production;
        semantic_action := cdr production;
        rule := for each symbol in rule collect
                  (if (intern symbol) member nonterminals then 
                     intern symbol
                   else
                     car rassoc(intern symbol, lex_codes));
        production := rule . semantic_action;
        productions_processed := production . productions_processed >>;
      if (w := get(intern x, 'lalr_produces)) then
        productions_processed := append(w, productions_processed);
      put(intern x, 'lalr_produces, productions_processed) >>
  end;

+++ lalr_process_productions compiled, 136 + 24 bytes

lalr_process_productions


symbolic procedure lalr_precalculate_first_sets;
  begin
    scalar more_added, x_first_set, rhs, w;
    repeat << 
      more_added := nil;
      for each x in nonterminals do <<
        x_first_set := get(x, 'lalr_first);
        for each production in lalr_productions x do <<
          rhs := car production;
          while rhs and 
                not numberp car rhs and 
                member(nil, (w := get(car rhs, 'lalr_first))) do <<
            x_first_set := union(delete(nil, w), x_first_set);
            rhs := cdr rhs >>;
          if null rhs then 
            x_first_set := union('(nil), x_first_set)
          else if numberp car rhs then 
            x_first_set := union(list car rhs, x_first_set)
          else
            x_first_set := union(get(car rhs, 'lalr_first), x_first_set) >>;
        if x_first_set neq get(x, 'lalr_first) then <<
          more_added := t;
          put(x, 'lalr_first, x_first_set) >> >>
    >> until not more_added
  end;

+++ lalr_precalculate_first_sets compiled, 117 + 36 bytes

lalr_precalculate_first_sets


symbolic procedure lalr_collect_nonterminals grammar;
  lalr_remove_duplicates 
    (for each productions in grammar collect intern car productions);

+++ lalr_collect_nonterminals compiled, 42 + 12 bytes

lalr_collect_nonterminals


symbolic procedure lalr_collect_terminals grammar; 
  begin
    scalar rhs_symbols;
    for each productions in grammar do 
      for each production in cdr productions do 
        for each symbol in car production do 
          if not (symbol member rhs_symbols) then
            rhs_symbols := symbol . rhs_symbols;
    return setdiff(rhs_symbols, nonterminals)
  end;

+++ lalr_collect_terminals compiled, 57 + 16 bytes

lalr_collect_terminals


symbolic procedure lalr_get_lex_codes terminals;
  begin
    scalar nonstandard_terminals, prev_lex_context, lex_codes;
    for each terminal in terminals do
      if stringp terminal then 
        nonstandard_terminals := terminal . nonstandard_terminals;
    prev_lex_context := lex_save_context();
    lex_cleanup();
    lex_keywords nonstandard_terminals;
    lex_context := lex_save_context();
    lex_codes := lex_export_codes();
    lex_restore_context(prev_lex_context);
    return lex_codes
  end;

+++ lalr_get_lex_codes compiled, 39 + 32 bytes

lalr_get_lex_codes








%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This section generates the LR0 item collection.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Generates the collection of LR(0) itemsets for the grammar (which must have
% already been analyzed by lalr_set_grammar, so that lalr_productions works
% and the symbols list exists).
%
% Effects: initializes itemset_collection and goto_table
%
% The algorithm is taken from the Dragon Book (Figure 4.33), but arranges to 
% process each itemset only once.
symbolic procedure lalr_generate_lr0_collection;
  begin
    scalar pending, previous_i, i_itemset, itemset, 
           goto_itemset, goto_itemset1, i_goto_itemset;
    itemset_collection := list (lalr_lr0_initial_itemset() . 0);
    pending := list car itemset_collection;    
    previous_i := 0;

    while pending do <<
      i_itemset := car pending;
      pending := cdr pending;
      itemset := car i_itemset;

      % For each grammar symbol, compute the goto itemset. If we've already
      % discovered this itemset, simply update the goto_table. If it's new, 
      % allocate it an index and add it to itemset_collection first. 
      for each x in symbols do <<
        if goto_itemset := lalr_compute_lr0_goto(itemset, x) then <<
          if goto_itemset1 := assoc(goto_itemset, itemset_collection) then
            i_goto_itemset := goto_itemset1  
          else <<
            i_goto_itemset := goto_itemset . (previous_i := previous_i + 1);
            itemset_collection := i_goto_itemset . itemset_collection;
            pending := i_goto_itemset . pending >>;
          lalr_add_goto(i_itemset, x, i_goto_itemset) >> >> >>;

    %% if !*lalr_verbose then 
    %%  lalr_print_lr0_collection()
  end;

+++ lalr_generate_lr0_collection compiled, 83 + 32 bytes

lalr_generate_lr0_collection


% Simply constructs the initial itemset, which is the closure of
% the itemset comprising only the initial production [S' -> .S].
symbolic procedure lalr_lr0_initial_itemset;
  begin
    scalar start_symbol, initial_item;
    start_symbol := caaar lalr_productions '!S!';
    initial_item := list('!S!', '!., start_symbol);
    return lalr_lr0_closure list initial_item
  end;

+++ lalr_lr0_initial_itemset compiled, 17 + 24 bytes

lalr_lr0_initial_itemset




% Implements the function GOTO (for LR(0) itemsets) described in the Dragon 
% Book. 
%
% Note: this procedure is not aware of itemset_collection or 
% goto_table, and returns brand new objects. The itemset parameter is a list 
% of LR(0) items (the index from itemset_collection is not included).  
symbolic procedure lalr_compute_lr0_goto(itemset, x);
  begin
    scalar result_kernel, result_item;
    for each item in itemset do 
      if (result_item := lalr_lr0_move_dot(item, x)) then
        result_kernel := result_item . result_kernel;
    return lalr_lr0_closure result_kernel
  end;

+++ lalr_compute_lr0_goto compiled, 29 + 16 bytes

lalr_compute_lr0_goto




% This procedure attempts to "move the dot" in an LR(0) item. Specifically, if
% for the LR(0) item [A -> bc.de], if d=x (the parameter x), then it returns
% [A -> bcd.e] and otherwise nil. 
symbolic procedure lalr_lr0_move_dot(item, x);
  begin
    scalar r;
    while not (car item = '!.) do <<
      r := car item . r;
      item := cdr item >>;
    item := cdr item;
    if not (item and car item = x) then return nil;
    item := car item . '!. . cdr item;
    while r do <<
      item := car r . item;
      r := cdr r >>;
    return item
  end;

+++ lalr_lr0_move_dot compiled, 38 + 12 bytes

lalr_lr0_move_dot




% Implements the function CLOSURE (for LR(0) items) described in the Dragon 
% Book. 
%
% Note: this procedure is not aware of itemset_collection or 
% goto_table, and returns brand new objects (though original items are 
% retained). The itemset parameter is a list of LR(0) items (the index from 
% itemset_collection is not included).
%
% Implementation is based on Figure 4.32 in the Dragon Book, although some 
% effort is made to avoid duplicate work.
symbolic procedure lalr_lr0_closure itemset;
  begin
    scalar added, pending, tail, x, rule, new_items, y;
    for each item in itemset do <<
      tail := cdr ('!. member item);
      if tail and (x := car tail) and idp x and not (x member pending) then 
        pending := x . pending >>;

    while pending do <<
      x := car pending;
      pending := cdr pending;
      added := x . added;

      for each production in lalr_productions x do << % [x -> abc] as (a b c)
        rule := car production;
        new_items := (x . '!. . rule) . new_items;
        if rule and (y := car rule) and idp y 
                           and not (y member added or y member pending) then 
          pending := y . pending >> >>;

    % new_items has no duplicates because we made sure to check the added list
    % but there may be overlap with the initial items in the itemset.
    return union(itemset, new_items) 
  end;

+++ lalr_lr0_closure compiled, 111 + 24 bytes

lalr_lr0_closure



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% This section converts the LR(0) itemset collection into the LALR collection.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Converts the collection of LR(0) itemsets for the grammar (which must have
% already been generated by lalr_generate_lr0_collection) to the LALR 
% collection.
%
% Effects: modifies itemset_collection
%
% The algorithm is adapted from the Dragon Book (Algorithm 4.63). 
symbolic procedure lalr_generate_collection;
  begin
    scalar itemset0, propagation_list;

    % First we must convert the items from their LR(0) format to a format that
    % can have lookaheads. We also take the opportunity to strip each itemset
    % down to its kernel. Note that we preserve the identity of the i_itemsets, 
    % because the goto_table links between them. 
    for each i_itemset in itemset_collection do 
      rplaca(i_itemset, lalr_lr0_itemset_to_lalr_kernel car i_itemset);

    % Hereafter all operations on the individual LALR items (adding lookaheads)
    % preserve their identity, because the propagation_list links between them.

    % Determine all spontaneously generated lookaheads and all item -> item
    % lookahead propagation pairs. 
    propagation_list := lalr_analyze_lookaheads();

    % Add the special lookahead 0 (end-of-input character $) to the initial
    % item [S' -> S]. 
    itemset0 := car rassoc(0, itemset_collection);
    lalr_add_lookahead(car itemset0, 0);

    % Propagate all lookaheads until the LALR collection is complete.
    lalr_propagate_lookaheads(propagation_list);

    % Expand out the kernels to the full itemsets.
    for each i_itemset in itemset_collection do 
      rplaca(i_itemset, lalr_closure car i_itemset);

    if !*lalr_verbose then 
      lalr_print_collection()
  end;

+++ lalr_generate_collection compiled, 63 + 48 bytes

lalr_generate_collection




% This procedure converts an LR0 itemset to its LALR kernel. This is really
% two separate jobs and perhaps I shouldn't have combined them. First, we 
% examine each item and only retain it if it is a kernel item. Second, we wrap
% each item (already a list, e.g. 
%     '(A a !. b c) corresponding to LR(0) item [A -> a.bc]
% in another list, which leaves room to stash lookahead symbols. 
symbolic procedure lalr_lr0_itemset_to_lalr_kernel itemset;
  begin
    scalar kernel;
    for each item in itemset do 
      if (car item = '!S!') or (cadr item neq '!.) then 
        kernel := (list item) . kernel;
    return kernel
  end;

+++ lalr_lr0_itemset_to_lalr_kernel compiled, 29 + 16 bytes

lalr_lr0_itemset_to_lalr_kernel




% This procedure destructively adds a lookahead symbol to a LALR item.
symbolic procedure lalr_add_lookahead(item, lookahead);
  if item then 
    rplacd(item, lookahead . cdr item)
  else 
    rplacd(item, list lookahead);

+++ lalr_add_lookahead compiled, 19 + 8 bytes

lalr_add_lookahead




% Repeatedly passes over a provided propagation_list, which links item pairs
% (src . dest), until all lookaheads from src are propagated to dest.
symbolic procedure lalr_propagate_lookaheads propagation_list;
  begin
    scalar more_propagated, src, dest;
    repeat <<
      more_propagated := nil;
      for each item_pair in propagation_list do <<
        src := car item_pair; dest := cdr item_pair;
        for each lookahead in cdr src do 
          if not (lookahead member (cdr dest)) then <<
            lalr_add_lookahead(dest, lookahead);
            more_propagated := t >> >> 
    >> until not more_propagated
  end;

+++ lalr_propagate_lookaheads compiled, 52 + 16 bytes

lalr_propagate_lookaheads




% This is the core of the LR(0)-to-LALR conversion algorithm, and is just a 
% wrapper (to iterate through all itemsets) around Algorithm 4.62 in the Dragon 
% Book. 
%
% Effects: adds all spontaneously generated lookaheads to the items in
%          itemset_collection (note: item identity is preserved)
%
% Returns: a list  of item pairs (src . dest), such that all lookaheads from
%          item src should propagate to item dest
symbolic procedure lalr_analyze_lookaheads;
  begin
    scalar propagation_list, lookaheads, dest_i_itemset, dest_item, dummy_item,
           byxd, xd, x, d;
    for each src_i_itemset in itemset_collection do 
      for each src_item in car src_i_itemset do << % Algorithm 4.62
        dummy_item := (car src_item) . '(-1); % -1 is the dummy lookahead #
        for each dummy_closure_item in lalr_closure list dummy_item do <<

          % dummy_closure_item: [B -> y.xd, u/v] where y,d are 0+ grammar 
          % symbols, x is 0-1 grammar symbols
          byxd := car dummy_closure_item; % [B - y.xd]
          lookaheads := cdr dummy_closure_item; % [u/v]

          if xd := cdr ('!. member byxd) then <<
            x := car xd; d := cdr xd;
            dest_i_itemset := lalr_goto(src_i_itemset, x);
            dest_item := lalr_item_with_rule(
                        lalr_lr0_move_dot(byxd,x), car dest_i_itemset);

            for each a in lookaheads do % now considering item [B -> y.xd, a]
              if a = -1 then % lookaheads propagate
                propagation_list := (src_item . dest_item) . propagation_list
              else % lookahead a is spontaneously generated
                lalr_add_lookahead(dest_item, a) >> >> >>;

    return propagation_list
  end;

+++ lalr_analyze_lookaheads compiled, 129 + 44 bytes

lalr_analyze_lookaheads




% Searches the given itemset for the LALR item with the given production rule.
% (Or in other words, with the given "LR(0) core".)
symbolic procedure lalr_item_with_rule(rule, itemset);
  begin
    scalar result;
    while itemset do <<
      if caar itemset = rule then <<
        result := car itemset;
        itemset := nil >>
      else 
        itemset := cdr itemset >>;
    return result
  end;

+++ lalr_item_with_rule compiled, 18 + 8 bytes

lalr_item_with_rule
  



% Computes the LALR closure of an itemset. Note: this procedure is not aware of 
% itemset_collection or goto_table, and returns brand new objects (though 
% original items are retained). The itemset parameter is a list of LALR items 
% (the index from itemset_collection is not included). 
%
% The implementation is essentially the algorithm from Figure 4.40 in the 
% Dragon Book, though some care is taken not to do duplicate work. 
%
% The added complexity over lalr_lr0_closure essentially comes from this: 
% suppose that at one iteration of the loop, the closure operation generates  
% the item [B -> y, a/b/c/d], but a previous iteration generated [B -> y, b/d].
% Then we need to add the lookaheads a/c to the existing [B -> y, b/d] object 
% (to create [B -> y, a/b/c/d], represented as '((B y) a/b/c/d)), but we only 
% want to add [B -> y, a/c] to the pending list.
symbolic procedure lalr_closure itemset;
  begin
    scalar pending, item, tail, x, gen_lookaheads, gen_rule, gen_item; 
    pending := itemset;
    while pending do <<
      item := car pending;
      pending := cdr pending;

      for each lookahead in cdr item do <<
        tail := cdr ('!. member car item);
        if tail and (x := car tail) and idp x then
          for each production in lalr_productions x do << % [B -> y]
            gen_lookaheads := lalr_first append(cdr tail, list lookahead);

            gen_rule := x . '!. . car production;
            gen_item := lalr_item_with_rule(gen_rule, itemset);
            if gen_item then 
              gen_lookaheads := setdiff(gen_lookaheads, cdr gen_item) 
            else <<
              gen_item := gen_rule . nil;
              itemset := gen_item . itemset >>;

            if gen_lookaheads then <<
              pending := (gen_rule . gen_lookaheads) . pending;
              for each gen_lookahead in gen_lookaheads do
                lalr_add_lookahead(gen_item, gen_lookahead) >> >> >> >>;
    return itemset
  end;

+++ lalr_closure compiled, 132 + 36 bytes

lalr_closure




symbolic procedure lalr_first string;
  begin
    scalar results, w;
    while string and
          not numberp car string and
          (nil member (w := get(car string, 'lalr_first))) do <<
      results := union(delete(nil, w), results);
      string := cdr string >>;
    if null string then results := nil . results
    else if numberp car string then results := union(list car string, results)
    else results := union(w, results);
    return results
  end;

+++ lalr_first compiled, 53 + 12 bytes

lalr_first




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% In this section, make_compressed_action_table examines the itemset_collection
%% and goto_table in order to make the ACTION portion of the ACTION/GOTO 
%% parser table described by the Dragon Book.
%%
%% The compression method is based off the discussion of compressed LALR 
%% parsing tables in the Dragon Book. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% reqs ordered itemset collection %% wait... does it? why?
symbolic procedure lalr_make_compressed_action_table;
  begin
    scalar table;
    table := mkvect sub1 length itemset_collection;
    for each i_itemset in itemset_collection do 
      putv(table, cdr i_itemset, lalr_make_compressed_action_row i_itemset);
    if !*lalr_verbose then
      lalr_print_compressed_action_table table;
    return table;
  end;

+++ lalr_make_compressed_action_table compiled, 36 + 24 bytes

lalr_make_compressed_action_table


symbolic procedure lalr_make_compressed_action_row i_itemset;
  begin
    scalar action_list;
    action_list := lalr_list_of_actions i_itemset;
    action_list := lalr_resolve_conflicts(action_list, cdr i_itemset);
    return lalr_make_compressed_action_row1 action_list;
  end;
*** lalr_resolve_conflicts called with 2 instead of 1 arguments 


+++ lalr_make_compressed_action_row compiled, 12 + 20 bytes

lalr_make_compressed_action_row


symbolic procedure lalr_resolve_conflicts(action_list, itemset_i); 
  begin
    scalar conflicting_actions, results, shift, reduce, chosen_action,
           shift_op, reduce_op, associativity, 
           shift_precedence, reduce_precedence;
    action_list := sort(action_list, function lesspcar);
    while action_list do <<
      conflicting_actions := list car action_list;
      action_list := cdr action_list;
      while action_list and caar action_list = caar conflicting_actions do <<
        conflicting_actions := car action_list . conflicting_actions;
        action_list := cdr action_list >>;

      shift := reduce := chosen_action := nil;
      if null cdr conflicting_actions then
        chosen_action := car conflicting_actions
      else
        for each action in conflicting_actions do <<
          if caadr action = 'shift then 
            shift := action
          else if null reduce then % handles accept as well?
            reduce := action
          else % reduce-reduce conflict b B keep first reduction seen
            lalr_warn_reduce_reduce_conflict(reduce, action, itemset_i);

          if shift and reduce then << % shift-reduce conflict
            shift_op := car shift; % terminal after dot
            for each symbol in cadr cadr reduce do % the rule
              if numberp symbol then
                reduce_op := symbol;

            if shift_op and reduce_op then <<
              shift_precedence := lalr_precedence shift_op;
              reduce_precedence := lalr_precedence reduce_op;
              if shift_precedence and reduce_precedence then 
                if shift_precedence = reduce_precedence then <<
                  associativity := lalr_associativity shift_op;
                  if associativity = '!:left then
                    shift := nil
                  else if associativity = '!:right then 
                    reduce := nil
                  else
                    shift := reduce := nil >>
                else if shift_precedence < reduce_precedence then
                  reduce := nil
                else 
                  shift := nil >> >> >>;

      if shift and reduce then 
        lalr_warn_shift_reduce_conflict(shift, reduce, itemset_i);
      chosen_action := chosen_action or shift or reduce;
      if chosen_action then
        results := chosen_action . results >>;
    return results
  end;
*** lalr_resolve_conflicts defined with 2 but previously called with 1 arguments
 


+++ lalr_resolve_conflicts compiled, 216 + 44 bytes

lalr_resolve_conflicts


symbolic procedure lalr_list_of_actions i_itemset;
  begin
    scalar actions, lhs, terminal, tail, rule, reduction_i, goto_i;
    for each item in car i_itemset do <<
      lhs := caar item;
      tail := cdr ('!. member car item);
      if tail and numberp car tail then <<
        terminal := car tail;
        goto_i := cdr lalr_goto(i_itemset, terminal);
        actions := list(terminal, list('shift, goto_i)) . actions >>
      else if null tail and lhs neq '!S!' then <<
        rule := delete('!., car item);
        reduction_i := lalr_reduction_index rule;
        for each lookahead in cdr item do 
          actions := list(lookahead, 
                          list('reduce, rule, reduction_i)) . actions >>
      else if null tail and lhs = '!S!' then 
        actions := list(0, '(accept)) . actions >>;
    return lalr_remove_duplicates actions;
  end;

+++ lalr_list_of_actions compiled, 115 + 44 bytes

lalr_list_of_actions


symbolic procedure lalr_remove_duplicates x;
  begin
    scalar r;
    for each a in x do
      if not member(a, r) then r := a . r;
    return reversip r
  end;

+++ lalr_remove_duplicates compiled, 29 + 8 bytes

lalr_remove_duplicates


symbolic procedure lalr_make_compressed_action_row1 action_list;
  begin
    scalar most_common_reduction, row, terminal, action_type;
    most_common_reduction := lalr_most_common_reduction action_list;
    for each action in action_list do 
      if cadr action neq most_common_reduction then <<
        terminal := car action;
        action_type := caadr action;
        if action_type = 'shift then 
          row := (terminal . cadadr action) . row
        else if action_type = 'accept then
          row := (terminal . 0) . row
        else if action_type = 'reduce then 
          row := (terminal . -(car cddadr action)) . row >>;
    if most_common_reduction then
      most_common_reduction := 
        if car most_common_reduction = 'accept then 0
        else -(caddr most_common_reduction);
    return row . most_common_reduction
  end;

+++ lalr_make_compressed_action_row1 compiled, 89 + 28 bytes

lalr_make_compressed_action_row1


symbolic procedure lalr_most_common_reduction action_list;
  begin
    scalar reduction_count, reduction, w;
    for each action in action_list do
      if caadr action = 'reduce or caadr action = 'accept then <<
        reduction := cadr action;
        if (w := assoc(action, reduction)) then rplacd(w, cdr w + 1)
        else reduction_count := (reduction . 1) . reduction_count >>;
    if reduction_count then <<
      w := car reduction_count;
      for each entry in cdr reduction_count do 
        if cdr entry > cdr w then 
          w := entry;
      return car w >>
    else
      return nil
  end;

+++ lalr_most_common_reduction compiled, 79 + 20 bytes

lalr_most_common_reduction


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% In this section, make_ examines the itemset_collection
%% and goto_table in order to make the GOTO portion of the ACTION/GOTO 
%% parser table described by the Dragon Book.
%%
%% The compression method is based off the discussion of compressed LALR 
%% parsing tables in the Dragon Book. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

symbolic procedure lalr_make_compressed_goto_table;
  begin
    scalar table, column;
    table := mkvect sub1 length nonterminals;
    for each x in nonterminals do % ordered by nonterminal code
      if x neq '!S!' then <<
        column := lalr_make_compressed_goto_column x;
        putv(table, get(x, 'lalr_nonterminal_code), column) >>;
    if !*lalr_verbose then 
      lalr_print_compressed_goto_table table;
    return table
  end;

+++ lalr_make_compressed_goto_table compiled, 44 + 32 bytes

lalr_make_compressed_goto_table


symbolic procedure lalr_make_compressed_goto_column x;
  begin
    scalar goto_list, column, most_common_dest;
    goto_list := for each entry in gethash(x, goto_table) collect
                (cdar entry . cddr entry);
    most_common_dest := lalr_most_common_dest goto_list;
    for each entry in goto_list do 
      if cdr entry neq most_common_dest then
        column := entry . column;
    return column . most_common_dest
  end;

+++ lalr_make_compressed_goto_column compiled, 78 + 20 bytes

lalr_make_compressed_goto_column


symbolic procedure lalr_most_common_dest goto_list;
  begin
    scalar dest_count, w;
    for each entry in goto_list do
      if (w := assoc(cdr entry, dest_count)) then rplacd(w, cdr w + 1)
      else dest_count := (cdr entry . 1) . dest_count;
    w := car dest_count;
    for each entry in cdr dest_count do if cdr entry > cdr w then w := entry;
    return car w
  end;

+++ lalr_most_common_dest compiled, 61 + 12 bytes

lalr_most_common_dest



%%%
%
%
% includes a useless reduction for S' -> S
symbolic procedure lalr_process_reductions;
  begin
    scalar reduction_codes, code, n_reductions, canonical_reduction, 
           coded_canonical_reduction, rhs_length, lhs, fn, 
           reduction_fn, reduction_lhs, reduction_rhs_length;

    code := -1;
    % print nonterminals; print lalr_productions car nonterminals; error(1,"");
    for each x in nonterminals do 
      for each production in lalr_productions x do <<
        canonical_reduction := (x . length car production) . cdr production;
        coded_canonical_reduction := assoc(canonical_reduction,reduction_codes);
        if null coded_canonical_reduction then <<
          coded_canonical_reduction := canonical_reduction . (code := code + 1);
          reduction_codes := coded_canonical_reduction . reduction_codes >>;
        rplacd(production, cdr coded_canonical_reduction) >>;

    n_reductions := code + 1;
    reduction_fn := mkvect sub1 n_reductions;
    reduction_lhs := mkvect16 sub1 n_reductions;
    reduction_rhs_length := mkvect8 sub1 n_reductions;
    for each coded_canonical_reduction in reduction_codes do <<
      code := cdr coded_canonical_reduction;
      rhs_length := cdaar coded_canonical_reduction;
      lhs := get(caaar coded_canonical_reduction, 'lalr_nonterminal_code);
      putv16(reduction_lhs, code, lhs);
      putv8(reduction_rhs_length, code, rhs_length);

      if (cdar coded_canonical_reduction) then <<
        fn := cdar coded_canonical_reduction;
        fn := lalr_construct_fn(fn, rhs_length) >>
      else
        fn := nil;
      putv(reduction_fn, code, fn) >>;

    return list(reduction_fn, reduction_rhs_length, reduction_lhs);
  end;

+++ lalr_process_reductions compiled, 164 + 56 bytes

lalr_process_reductions




symbolic procedure lalr_reduction_index rule;
  begin
    scalar x, rhs;
    x := car rule; rhs := cdr rule;
    return cdr assoc(rhs, lalr_productions x)
  end;

+++ lalr_reduction_index compiled, 14 + 12 bytes

lalr_reduction_index



symbolic procedure lalr_construct_fn(lambda_expr, args_n);
  begin
    scalar fn;
    fn := gensym();
    lambda_expr := 'lambda  . lalr_make_arglist args_n . list lambda_expr;
    putd(fn, 'expr, lambda_expr) where !*pwrds = nil;
    return fn
  end;

+++ lalr_construct_fn compiled, 32 + 36 bytes

lalr_construct_fn


symbolic procedure lalr_make_arglist n;
  for i := 1:n collect
    intern list2string ('!$ . explode2 i);

+++ lalr_make_arglist compiled, 52 + 20 bytes

lalr_make_arglist



end;

nil

% genparserprint.red

% Copyright Zach Hauser and Arthur Norman, 2016

% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions
% are met:
%
%    * Redistributions of source code must retain the relevant
%      copyright notice, this list of conditions and the following
%      disclaimer.
%    * Redistributions in binary form must reproduce the above
%      copyright notice, this list of conditions and the following
%      disclaimer in the documentation and/or other materials provided
%      with the distribution.
%
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
% "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
% LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
% A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
% OWNERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
% SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
% LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
% DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
% THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
% (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
% OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
% 

% $Id: $

module 'genparserprint;


nil


symbolic procedure lalr_print_compressed_action_table action_table;
  begin
    scalar n_itemsets, row, default;
    n_itemsets := length itemset_collection;
    princ "=== ACTION TABLE ==="; terpri();
    princ "STATE"; ttab 6; princ "TERMINAL"; ttab 20; princ "ACTION"; terpri();
    for state:=0 : (sub1 n_itemsets) do << 
      row := car getv(action_table, state);
      default := cdr getv(action_table, state);
      prin state; 
      for each entry in row do <<
        ttab 6; lalr_prin_symbol car entry; ttab 20;
        lalr_prin_action cdr entry; terpri() >>;  
      if default then <<
        ttab 6; princ "<any>"; ttab 20;   
        lalr_prin_action default; terpri() >> >>;
    terpri();
  end;

+++ lalr_print_compressed_action_table compiled, 102 + 52 bytes

lalr_print_compressed_action_table


symbolic procedure lalr_print_compressed_goto_table goto_table;
  begin 
    scalar code, row, default;
    princ "=== GOTO TABLE ==="; terpri();
    princ "NONTERMINAL"; ttab 20; princ "SRC"; ttab 28; princ "DEST"; terpri();
    for each nonterminal in delete('!S!', nonterminals) do <<
      code := get(nonterminal, 'lalr_nonterminal_code);
      row := car getv(goto_table, code);
      default := cdr getv(goto_table, code);
      lalr_prin_nonterminal code;
      for each entry in row do <<
        ttab 20; prin car entry; ttab 28; print cdr entry >>;
      if default then <<
        ttab 20; princ "<any>"; ttab 28; print default >> >>;
    terpri();
  end;

+++ lalr_print_compressed_goto_table compiled, 113 + 60 bytes

lalr_print_compressed_goto_table


symbolic procedure lalr_prin_action action;
  if action = nil then 
    princ " "
  else if action > 0 then << 
    princ "shift to state "; 
    prin action >>
  else if action = 0 then 
    princ "accept"
  else 
    lalr_prin_reduction (-action);

+++ lalr_prin_action compiled, 30 + 28 bytes

lalr_prin_action


symbolic procedure lalr_prin_reduction code;
  begin
    scalar reduction_fn, reduction_rhs_length, reduction_lhs, fn;
    reduction_fn := first reduction_info; 
    reduction_rhs_length := second reduction_info;
    reduction_lhs := third reduction_info;
    princ "reduce by #"; prin code; princ ": ";
    lalr_prin_nonterminal getv16(reduction_lhs, code); 
    princ " -> ["; prin getv8(reduction_rhs_length, code); princ " symbols] ";
    if (fn := getv(reduction_fn, code)) then
      prin car cdddr getd fn;
  end;

+++ lalr_prin_reduction compiled, 56 + 56 bytes

lalr_prin_reduction


symbolic procedure lalr_print_lr0_collection; 
  begin
    scalar i_goto;
    printc "=== LR(0) ITEMSET COLLECTION ==="; terpri();
    for each i_itemset in reverse itemset_collection do <<
      princ "Itemset "; prin cdr i_itemset; terpri();
      for each item in sort(car i_itemset, function ordp) do <<
        princ " "; lalr_prin_symbol car item; princ " ->"; 
        for each x in cdr item do << princ " "; lalr_prin_symbol x >>;
        terpri() >>;
      for each x in symbols do 
        if i_goto := lalr_goto(i_itemset, x) then <<
          princ "GOTO("; lalr_prin_symbol x; 
          princ ") = state "; prin cdr i_goto;
          terpri() >>;
      terpri() >>
  end;

+++ lalr_print_lr0_collection compiled, 116 + 56 bytes

lalr_print_lr0_collection


symbolic procedure lalr_print_collection; 
  begin
    scalar i_goto;
    printc "=== LALR ITEMSET COLLECTION ==="; terpri();
    for each i_itemset in reverse itemset_collection do <<
      princ "Itemset "; prin cdr i_itemset; terpri();
      for each item in sort(car i_itemset, function ordp) do <<
        princ " "; lalr_prin_symbol caar item; princ " ->"; 
        for each x in cdar item do << princ " "; lalr_prin_symbol x >>;
        princ " [";
        for each remaining_lookaheads on cdr item do <<
          lalr_prin_symbol car remaining_lookaheads;
          if length remaining_lookaheads = 1 then 
            princ "]"
          else 
            princ "/" >>; 
        terpri() >>;
      for each x in symbols do 
        if i_goto := lalr_goto(i_itemset, x) then <<
          princ "GOTO("; lalr_prin_symbol x; princ ") = "; prin cdr i_goto;
          terpri() >>;
      terpri() >>
  end;

+++ lalr_print_collection compiled, 149 + 72 bytes

lalr_print_collection


symbolic procedure lalr_print_first_information;
  <<
    printc "=== FIRST sets for each nonterminal ===";
    for each nt in nonterminals do <<
      lalr_prin_symbol nt; princ ":"; ttab 20;
      for each terminal in get(nt, 'lalr_first) do <<
        lalr_prin_symbol terminal; princ " " >>; 
      terpri() >>;
    terpri()
  >>;

+++ lalr_print_first_information compiled, 50 + 36 bytes

lalr_print_first_information


symbolic procedure lalr_print_terminals_and_codes terminals;
  << 
    printc "=== Terminal symbols ==="; 
    for each terminal in terminals do <<
      princ "   "; lalr_prin_symbol terminal; 
      princ " ["; prin terminal; princ "]";
      if (lalr_precedence terminal) or (lalr_associativity terminal) then <<
        princ " (precedence "; prin lalr_precedence terminal; princ ", ";
        for each c in cdr explode2 lalr_associativity terminal do princ c; 
        princ " associativity)" >>;
      terpri() >>;
    terpri()
  >>;

+++ lalr_print_terminals_and_codes compiled, 82 + 48 bytes

lalr_print_terminals_and_codes


symbolic procedure lalr_print_nonterminals_and_productions;
  <<  
    print "=== Nonterminal symbols ===";
    for each nt in nonterminals do <<
      princ "["; prin get(nt, 'lalr_nonterminal_code); princ "] ";
      lalr_prin_symbol nt;
      begin 
        scalar separator;
        separator := ":";
        for each production in lalr_productions nt do <<
          ttab 20; princ separator; princ " ";
          separator := "|";
          lalr_prin_rhs car production;
          if posn() > 48 then terpri(); ttab 48;
          princ "{ "; lalr_prin_semantic_action cdr production; princ " }";
          terpri() >>
      end;
      terpri() >>;
    terpri()
  >>;

+++ lalr_print_nonterminals_and_productions compiled, 98 + 72 bytes

lalr_print_nonterminals_and_productions


symbolic procedure lalr_prin_semantic_action semantic_action;
  prin semantic_action;

+++ lalr_prin_semantic_action compiled as link to prin

lalr_prin_semantic_action


symbolic procedure lalr_prin_rhs rhs;
  if rhs = nil then 
    princ "<empty>"
  else 
    for each sym in rhs do <<
      lalr_prin_symbol sym;
      princ " " >>;

+++ lalr_prin_rhs compiled, 24 + 20 bytes

lalr_prin_rhs


symbolic procedure lalr_prin_symbol sym;
  if sym = 0 then 
    princ "$"
  else if numberp sym then
    for each c in explode2 cdr assoc(sym, terminal_codes) do princ c
  else 
    for each c in explode2uc sym do princ c;

+++ lalr_prin_symbol compiled, 51 + 24 bytes

lalr_prin_symbol


symbolic procedure lalr_prin_nonterminal code;
  for each c in explode2uc cdr assoc(code, nonterminal_codes) do princ c;

+++ lalr_prin_nonterminal compiled, 22 + 16 bytes

lalr_prin_nonterminal



symbolic procedure lalr_warn_reduce_reduce_conflict(reduce1, reduce2, state);
  <<
    if not zerop posn() then terpri();
    princ "+++++ Reduce/reduce conflict in itemset #"; prin state;
    princ " on lookahead "; lalr_prin_symbol car reduce1; terpri();
    princ "Reduction #1: "; lalr_prin_production cadr cadr reduce1; terpri();
    princ "Reduction #2: "; lalr_prin_production cadr cadr reduce2; terpri();
    printc "Resolved in favour of reduction #1";
    terpri()
  >>;

+++ lalr_warn_reduce_reduce_conflict compiled, 45 + 36 bytes

lalr_warn_reduce_reduce_conflict


symbolic procedure lalr_prin_production production;
  <<
    lalr_prin_symbol car production;
    princ " -> ";
    lalr_prin_rhs cdr production
  >>;

+++ lalr_prin_production compiled, 10 + 20 bytes

lalr_prin_production



symbolic procedure lalr_warn_shift_reduce_conflict(shift, reduce, state);
  begin
    scalar s;
    if not zerop posn() then terpri();
    princ "+++ Shift/reduce conflict in itemset #"; prin state; 
    princ " on lookahead "; lalr_prin_symbol car shift; terpri();
    princ "Reduce: "; lalr_prin_production cadr cadr reduce; terpri();
    princ "Shift: to state #"; prin cadr cadr shift; terpri(); 
    printc "Resolved in favour of the shift operation";
    terpri()
  end;
*** local variable s in procedure lalr_warn_shift_reduce_conflict not used 


+++ lalr_warn_shift_reduce_conflict compiled, 47 + 36 bytes

lalr_warn_shift_reduce_conflict


endmodule;


nil


end;

nil


(3 . 3)

% Test cases for the parser generator. This all runs in symbolic mode...


%
% This is where (for now) I will put documentation of the syntax I
% will use when creating a grammer. There is a main function called
% lalr_create_parser and that is passed a list that describes
% a grammar. It is in the form of a sequence of productions, and the first
% one given is taken to be the top-level target.
%
% Each production is in the form
%     (LHS   ((rhs1.1 rhs1.2 ...) a1.1 a1.2 ...)
%            ((rhs2.1 rhs2.1 ...) a2.1 a2.2 ...)
%            ...)
% which in regular publication style for grammars might be interpreted
% as meaning
%      LHS ::= rhs1.1 rhs1.2 ... { a1.1 a1.2 ... }
%          |   rhs2.1 rhs2.2 ... { a2.1 a2.2 ... }
%          ...
%          ;
%
% Each LHS is treated as a non-terminal symbol and is specified as a simple
% name. Note that by default the Reduce parser will be folding characters
% within names to lower case and so it will be best to choose names for
% non-terminals that are unambiguous even when case-folded, but I would like
% to establish a convention that in source code they are written in capitals.
%
% The rhs items may be either non-terminals (identified because they are
% present in the left hand side of some production) or terminals. Terminal
% symbols can be specified in two different ways.
% The lexer has built-in recipies that decode certain sequences of characters
% and return the special markers for !:symbol, !:number, !:string, !:list for
% commonly used cases. In these cases the variable yylval gets left set
% to associated data, so for instance in the case of !:symbol it gets set
% to the particular symbol concerned.
% The token type :list is used for Lisp or rlisp-like notation where the
% input contains
%     'expression
% or  `expression
% so for instance the input `(a b c) leads to the lexer returning !:list and
% yylvel being set to (backquote (a b c)). This treatment is specialised for
% handling rlisp-like syntax.
%
% Other terminals are indicated by writing a string. That may either
% consist of characters that would otherwise form a symbol (ie a letter
% followed by letters, digits and underscores) or a sequence of
% non-alphanumeric characters. In the latter case if a sequence of three or
% more punctuation marks make up a terminal then all the shorter prefixes
% of it will also be grouped to form single entities. So if "<-->" is a
% terminal then '<', '<-' and '<--' will each by parsed as single tokens, and
% any of them that are not used as terminals will be classified as !:symbol.
%
% As well as terminals and non-terminals (which are wrirrent as symbols or
% strings) it is possible to write one of
%     (OPT s1 s2 ...)           0 or 1 instances of the sequence s1, ...
%     (STAR s1 s2 ...)          0, 1, 2, ... instances
%     (PLUS s1 s2 ...)          1, 2, 3, ... instances
%     (LIST sep s1 s2 ...)      like (STAR s1 s2 ...) but with the single
%                               item sep between each instance.
%     (LISTPLUS sep s1 ...)     like (PLUS s2 ...) but with sep interleaved.
%     (OR s1 s2 ...)            one or other of the tokens shown.
%
% When the lexer processes input it will return a numeric code that identifies
% the type of the item seen, so in a production one might write
%     (!:symbol ":=" EXPRESSION)
% and as it recognises the first two tokens the lexer will return a numeric
% code for !:symbol (and set yylval to the actual symbol as seen) and then
% a numeric code that it allocates for ":=". In the latter case it will
% also set yylval to the symbol !:!= in case that is useful.
%
% Precedence can be set using lalr_precedence. See examples lower down in this
% file.

% Limitations are
% (1) At present the parser generator will not cope with large grammars
%     because it does not merge rules promptly enough.
% (2) The lexer is hand-written and can not readily be reconfigured for
%     use with languages other than rlisp. For instance it has use of "!"
%     as a character escape built into it.
%
%


symbolic;


nil


% Before testing parser generation I will demonstrate the lexer..
% If I was jumpy about the exact behaviour of the lexer I could go
%               on tracelex;
% to get some more tracing.

lex_cleanup();


nil


lex_keywords '("begin" "<=>" "<==");


nil


% The output from this is expected to be

%  Result: (2 symbol)
%  Result: (4 200)
%  Result: (4 3.542)
%  Result: (3 "a string")
%  Result: (2 nil)
%  Result: (5 (quote (quoted lisp)))
%  Result: (5 (backquote (backquoted (!, comma) (!,!@ comma_at))))
%  Result: (2 !+)
%  Result: (7 !<!=!>)
%  Result: (2 !-)
%  Result: (2 !=)
%  Result: (2 !>)
%  Result: (9 !<)
%  Result: (8 !<!=)
%  Result: (5 begin)
%  Result: (2 !;)
%  Result: (2 !;)
%  Result: (2 !;)
%
%  nil

% The row of "; ; ;" at the end provides some protection so that
% if faults in the lexer were to cause it to read more or less than it ought
% to then what is left over is reasonably likely to remain as valid rlisp
% syntax and so the rest of this test file will be able to continue happily.


<< off echo;
   lex_init();
   for i := 1:18 do <<
     tt := yylex();
     if not zerop posn() then terpri();
     princ "Result: ";
     print list(tt, yylval) >>;
   on echo >>;

Result: (1 symbol)
Result: (3 200)
Result: (3 3.542)
Result: (2 "a string")
Result: (4 (quote (quoted lisp)))
Result: (4 (backquote (backquoted (!, comma) (!,!@ comma_at))))
Result: (1 !+)
Result: (6 !<!=!>)
Result: (1 !-)
Result: (1 !=)
Result: (1 !>)
Result: (8 !<)
Result: (7 !<!=)
Result: (5 begin)
Result: (1 !;)
Result: (1 !;)
Result: (1 !;)
Result: (1 !;)

nil



on lalr_verbose;


nil


% Here I set up a sample grammar
%    S' -> S
%    S  -> C C        { }
%    C  -> "c" C      { }
%        | "d"        { }
% This is example 4.42 from Aho, Sethi and Ullman's Red Dragon book.
% It is example 4.54 in the more recent Purple book.

% Note that this grammar will introduce "c" and "d" as keywords rather than
% being general symbols. When I construct a subsequent grammar that will
% undo that setting. I will omit semantic actions here so that the default
% action of building a form of tree is used.



grammar := '(
  (s  ((c c)    )   % One production for S, no semantic actions
  )
  (c  (("c" c)  )   % First production for C
      (("d")    )   % Second production for C
  ));


((s ((c c))) (c (("c" c)) (("d"))))


lalr_create_parser(nil, grammar);

=== Terminal symbols ===
   d [6]
   c [5]

"=== Nonterminal symbols ==="
[-1] S'
[0] S
[1] C

=== FIRST sets for each nonterminal ===
S':                 
S:                  
C:                  


+++ Error attempt to take car of an atom: nil
Inside: lalr_lr0_initial_itemset
Inside: lalr_generate_lr0_collection
Inside: lalr_create_parser
Arg 1: nil
Arg 2: ((s ((c c))) (c (("c" c)) (("d"))))

Cont? (Y or N)


eType Y or N
n

+++ Error unset variable: d

Inside: filenderr
Inside: token1
Inside: scan
Inside: command1
Inside: command

Inside: filenderr
Inside: token1
Inside: scan
Inside: command1
Inside: command

Inside: filenderr
Inside: token1
Inside: scan
Inside: command1
Inside: command

Inside: filenderr
Inside: token1
Inside: scan
Inside: command1
Inside: command

Inside: filenderr
Inside: token1
Inside: scan
Inside: command1
Inside: command

*** End-of-file read 


End of Lisp run after 0.07+0.09 seconds

+++ Transcript closed at end of run +++
