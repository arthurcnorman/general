\chapter{Thoughts from Stephen Watt to merge into Introduction}

Should computing be difficult?    With inexpensive, powerful hardware, a
multitude of web-based services, and vibe coding, isn't computing easier
than ever before?  Let us take the film industry as a metaphor.

When one wishes to watch a film these days, one turns on the television,
scrolls through the offerings of a streaming service, picks a title, and
watches.   There are people and scenes in the film.  The people go places,
do things and talk to each other.   How hard can it be?   Well, making a
film can be the work of hundreds, if not thousands, of people.  The people
who scout for locations in the film, the make up artists, the
lighting technicians, the foley artists who add sound effects, and hosts of
others, work in ways that are invisible in the final film.    Directors may
use different colour schemes intentionally for different scenes.  All this
is to say nothing of the talents of the actors who must portray the subtle
interactions that are not consciously noted, but must be exaggerated
just-so to be captured on film.   Tying this together in one coherent whole
is a labourious art.   You don't see it unless you know it.   You see it
when it is missing.

The same holds for computing.   One cold argue that computing well is, in
fact, harder today than ever before.   As in making a film, there are
thousands of considerations that must mesh together to form a coherent
system.    The number of hardware and software aspects to be considered is
many times greater than the mythical ``difficult'' days of decades past.
There are so many considerations that it is exceedingly rare to find
someone who understands the entire scope and how the parts fit.

This book is not about making computing {\em more} difficult than it needs to
be -- it is about making computing {\em only} difficult, when done properly,
rather than impossible.

